{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import *\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.gpuarray as gpuarray\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMEVENTS = 50\n",
    "AVENUMPARTICLES = 10\n",
    "\n",
    "numjets = np.random.poisson(AVENUMPARTICLES, NUMEVENTS)\n",
    "stops = np.cumsum(numjets, dtype=np.int)\n",
    "starts = np.zeros_like(stops)                              # Starts array\n",
    "starts[1:] = stops[:-1]\n",
    "offsets = np.zeros(len(numjets)+1, dtype=np.int)\n",
    "offsets[1:] = stops\n",
    "data = np.random.randint(low=0,high=10,size=stops[-1], dtype=np.int)\n",
    "len_arr = np.array([stops[-1]]).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_offsets = gpuarray.to_gpu_async(offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit()\n",
    "def vectorized_search(offsets, content):\n",
    "    index = np.arange(len(content), dtype=int)                     # threadIdx.x on CUDA\n",
    "    below = np.zeros(len(content), dtype=int)                      # just below = 0 on CUDA\n",
    "    above = np.ones(len(content), dtype=int) * (len(offsets) - 1)  # same for above\n",
    "    while True:\n",
    "        middle = (below + above) // 2\n",
    "\n",
    "        change_below = offsets[middle + 1] <= index                   # which \"belows\" must we change?\n",
    "        change_above = offsets[middle] > index                        # which \"aboves\"?\n",
    "\n",
    "        if not np.bitwise_or(change_below, change_above).any():    # neither? great! we're done!\n",
    "            break\n",
    "        else:\n",
    "            below = np.where(change_below, middle + 1, below)      # vectorized \"if\" statement\n",
    "            above = np.where(change_above, middle - 1, above)      # this is the only branch\n",
    "\n",
    "    return middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = vectorized_search(offsets, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_parents = gpuarray.to_gpu(parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = SourceModule('''\n",
    "__global__ void seg_warp_reduce(int* arr, int* parents,int* arr_len)\n",
    "{\n",
    "    int tid = threadIdx.x + blockIdx.x*blockDim.x;\n",
    "    \n",
    "    if (tid > arr_len[0])\n",
    "        return;\n",
    "    \n",
    "    int thread_id = threadIdx.x;\n",
    "    int warp_size = 32;\n",
    "    int lane = thread_id%warp_size;\n",
    "    \n",
    "    if (lane >=1 && parents[tid]==parents[tid-1])\n",
    "      arr[tid] = max(arr[tid], arr[tid-1]);\n",
    "     \n",
    "    if (lane >=2 && parents[tid]==parents[tid-2])\n",
    "     arr[tid] = max(arr[tid], arr[tid-2]);\n",
    "     \n",
    "    if (lane >=4 && parents[tid]==parents[tid-4])\n",
    "        arr[tid] = max(arr[tid], arr[tid-4]);\n",
    "      \n",
    "    if (lane >=8 && parents[tid]==parents[tid-8])\n",
    "        arr[tid] = max(arr[tid], arr[tid-8]);\n",
    "      \n",
    "    if (lane >=16 && parents[tid]==parents[tid-16])\n",
    "        arr[tid] = max(arr[tid], arr[tid-16]);\n",
    "       \n",
    "    \n",
    "}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod.get_function('seg_warp_reduce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_data = gpuarray.to_gpu(data)\n",
    "num_threads_per_block = 32\n",
    "num_blocks = int(np.ceil(stops[-1]/num_threads_per_block))\n",
    "func(gpu_data,gpu_parents,cuda.In(len_arr), block=(num_threads_per_block,1,1), grid=(int(num_blocks),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 9, 8, 8, 9, 8, 9, 9, 9, 5, 8, 9, 7, 9, 8, 9, 8, 8, 8, 9, 9, 9,\n",
       "       9, 9, 8, 9, 9, 9, 9, 9, 8, 7, 9, 8, 9, 8, 4, 9, 8, 9, 9, 8, 9, 9, 8,\n",
       "       8, 9, 6, 9])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_data = gpu_data.get()\n",
    "max_arr = kernel_data[stops-1]\n",
    "max_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_at_offsets = np.zeros_like(offsets)\n",
    "reduce_at_offsets[1:] = stops-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_max = np.maximum.reduceat(data, reduce_at_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "arr1: [6 0 3 2 8 4 3 6 8 7]\n",
      "max from gpu: 8   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr2: [7 5 3 8 6]\n",
      "max from gpu: 8   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr3: [3 9 7 3 5 8 6 1]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr4: [9 0 6 3 0 6 0 3 5 6 4 8]\n",
      "max from gpu: 8   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr5: [6 3 2 5 8]\n",
      "max from gpu: 8   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr6: [8 9 4 3 2 8 2 9 8 0 6]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr7: [2 0 7 5 1 8 4 1 8 0]\n",
      "max from gpu: 8   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr8: [8 3 5 2 3 2 9]\n",
      "max from gpu: 9   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr9: [3 6 4 9 4 6 8 9 5 8 4 7 3]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr10: [7 7 4 1 3 1 0 9 1]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr11: [3 9 0 3 3 9 4 3 5 4]\n",
      "max from gpu: 5   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr12: [6 5 8 8 1 7 1 3]\n",
      "max from gpu: 8   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr13: [7 4 0 2 9]\n",
      "max from gpu: 9   max from numpy: 7 \n",
      "\n",
      " \n",
      "arr14: [4 7 1 7 4 0 4 5 4]\n",
      "max from gpu: 7   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr15: [2 1 3 8 3 0 5 2 7 7 9 1 6]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr16: [8 4 4 8 4 6 7 5 7]\n",
      "max from gpu: 8   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr17: [1 3 0 9 4 3 2 3 2 8 2 8 8 2]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr18: [5 3 5 1 8 0]\n",
      "max from gpu: 8   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr19: [8 0 1 7 7 0 7 1 1 0 4 6 0 2]\n",
      "max from gpu: 8   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr20: [7 4 1 6 6 8 4 3 2 8 0 5]\n",
      "max from gpu: 8   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr21: [0 5 9 4 0 1 0 8]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr22: [7 6 3 9]\n",
      "max from gpu: 9   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr23: [0 4 6 0 1 4 1 8 2 9 0]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr24: [7 4 2 9 7 8 6]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr25: [1 4 4 1 9 4 3]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr26: [7 0 4 4 5 8 1 2 5 8 8 0]\n",
      "max from gpu: 8   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr27: [9 9 4 6 7 3 0 1 5 1 4 9 9 0 2]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr28: [1 4 3 0 9 5 9 1 1 7 9 4 6 5]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr29: [6 9 8 2 4 0 6 3 8 6]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr30: [3 3 9 4 3 9 2 8]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr31: [7 2 1 2 6 9]\n",
      "max from gpu: 9   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr32: [7 1 1 5 8]\n",
      "max from gpu: 8   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr33: [3 7 7 1 4 4 2 3 1]\n",
      "max from gpu: 7   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr34: [1 9 2 0 3 1 6 2 2 9 0 2 4]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr35: [6 2 8 7 1 5 3 3 0]\n",
      "max from gpu: 8   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr36: [9 4 3 2 7]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr37: [2 6 8 4 2 8 3]\n",
      "max from gpu: 8   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr38: [2 2 4 2 1 4 0 1]\n",
      "max from gpu: 4   max from numpy: 4 \n",
      "\n",
      " \n",
      "arr39: [3 9 9 1]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr40: [8 8 6 5 5 1 4 8 6 7]\n",
      "max from gpu: 8   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr41: [9 0 4 1 4 3 2]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr42: [8 8 5 3 7 9 2]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr43: [6 0 3 4 2 9 4 7 8 0 8]\n",
      "max from gpu: 8   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr44: [3 9 3 2 6 0 5 1 1 2]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr45: [4 9 3 0 6 1 7 1 5 9 7 5]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr46: [7 6 1 6 4 5 3 8]\n",
      "max from gpu: 8   max from numpy: 7 \n",
      "\n",
      " \n",
      "arr47: [7 3 8 3 5 2 3 6 0 8 4 2 1 2]\n",
      "max from gpu: 8   max from numpy: 8 \n",
      "\n",
      " \n",
      "arr48: [9 1 5 4 2 3 2 1 5]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr49: [4 9 4 3 3 6 6 2 6]\n",
      "max from gpu: 6   max from numpy: 9 \n",
      "\n",
      " \n",
      "arr50: [0 0 1 6 1 1 5 9 7 3]\n",
      "max from gpu: 9   max from numpy: 9 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(starts)):\n",
    "    print (\" \\narr{}: {}\\nmax from gpu: {}   max from numpy: {} \\n\".format(i+1, data[starts[i]:stops[i]], max_arr[i],np_max[i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
